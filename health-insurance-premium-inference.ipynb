{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Regression with an Insurance Dataset (Test Data Preprocessing + Inference)\n",
    "---\n",
    "##### Source: **Kaggle Playground Prediction Competition**\n",
    "##### Course Title: **DAMO-510-4: Winter 2025 Predictive Analytics**\n",
    "##### Professor Name: **Professor Ali El-Sharif**\n",
    "##### Submission Date: **March 9, 2025**\n",
    "##### Submitted By:\n",
    "1. **Denisse C. Cortes (NF1007936)**\n",
    "2. **Dev D. Rabadia (NF1005560)**\n",
    "3. **Miko L. Tan (NF1008647)**\n",
    "4. **Rosario D. Torres (NF1001385)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T21:43:56.220730Z",
     "iopub.status.busy": "2025-03-09T21:43:56.220456Z",
     "iopub.status.idle": "2025-03-09T21:43:56.226581Z",
     "shell.execute_reply": "2025-03-09T21:43:56.225567Z",
     "shell.execute_reply.started": "2025-03-09T21:43:56.220708Z"
    }
   },
   "source": [
    "The data model for this project is a regression-based model designed to predict insurance premium amounts. The model uses a variety of features, including numerical variables (such as age, annual income, and health score) and categorical variables (such as gender, marital status, and policy type) to estimate the target variable: the insurance premium amount. The dataset incorporates several features with skewed distributions and missing values, which will be handled through appropriate preprocessing techniques. Outliers in the dataset, such as those found in the \"Previous Claims\" feature, will also be addressed to improve model accuracy and robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "# insurance_test_data = pd.read_csv(\"/kaggle/input/playground-series-s4e12/test.csv\")\n",
    "insurance_test_data = pd.read_csv(\"kaggle/input/playground-series-s4e12/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best trained model\n",
    "# best_model = joblib.load(\"kaggle/input/hip-best-model/scikitlearn/xgb_rscv_v1.pkl/1/health-insurance-premium-best-model.pkl\")\n",
    "best_model = joblib.load(\"kaggle/working/health-insurance-premium-best-model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Exploratory Data Analysis (EDA)\n",
    "# missing_data = insurance_test_data.isnull().sum()\n",
    "# missing_percentage = (missing_data / len(insurance_test_data)) * 100\n",
    "# missing_info = pd.DataFrame({\n",
    "#     'Missing Count': missing_data,\n",
    "#     'Missing Percentage': missing_percentage,\n",
    "# })\n",
    "# def categorize_missing_data(percentage):\n",
    "#     if percentage <= 5:\n",
    "#         return 'Small (1-5%)'\n",
    "#     elif 5 < percentage <= 20:\n",
    "#         return 'Moderate (5-20%)'\n",
    "#     elif 20 < percentage <= 40:\n",
    "#         return 'High (20-40%)'\n",
    "#     else:\n",
    "#         return 'Very High (40%+)'\n",
    "# missing_info['Classification'] = missing_info['Missing Percentage'].apply(categorize_missing_data)\n",
    "# missing_info = missing_info.sort_values(by='Missing Percentage', ascending=False)\n",
    "\n",
    "# #### Handling Missing Data (excluding Premium Amount)\n",
    "# if missing_info.loc[\"Age\"][\"Missing Percentage\"] < 5:\n",
    "#     insurance_test_data.dropna(subset=[\"Age\"], inplace=True)\n",
    "# else:\n",
    "#     insurance_test_data[\"Age\"].fillna(insurance_test_data[\"Age\"].median(), inplace=True)\n",
    "# No dropping of records rule for Test dataset\n",
    "insurance_test_data.loc[:, \"Age\"] = insurance_test_data[\"Age\"].fillna(insurance_test_data[\"Age\"].median())\n",
    "insurance_test_data.loc[:, \"Gender\"] = insurance_test_data[\"Gender\"].fillna(\"Unknown\")\n",
    "# if missing_info.loc[\"Annual Income\"][\"Missing Percentage\"] < 5:\n",
    "#     insurance_test_data.dropna(subset=[\"Annual Income\"], inplace=True)\n",
    "# else:\n",
    "#     insurance_test_data[\"Annual Income\"].fillna(insurance_test_data[\"Annual Income\"].median(), inplace=True)\n",
    "insurance_test_data.loc[:, \"Annual Income\"] = insurance_test_data[\"Annual Income\"].fillna(insurance_test_data[\"Annual Income\"].median())\n",
    "insurance_test_data.loc[:, \"Marital Status\"] = insurance_test_data[\"Marital Status\"].fillna(\"Single\")\n",
    "insurance_test_data.loc[:, \"Number of Dependents\"] = insurance_test_data[\"Number of Dependents\"].fillna(0)\n",
    "insurance_test_data.loc[:, \"Education Level\"] = insurance_test_data[\"Education Level\"].fillna(\"Unknown\")\n",
    "insurance_test_data.loc[:, \"Occupation\"] = insurance_test_data[\"Occupation\"].fillna(\"Unemployed\")\n",
    "insurance_test_data.loc[:, \"Health Score\"] = insurance_test_data[\"Health Score\"].fillna(0)\n",
    "insurance_test_data.loc[:, \"Location\"] = insurance_test_data[\"Location\"].fillna(\"Unknown\")\n",
    "insurance_test_data.loc[:, \"Policy Type\"] = insurance_test_data[\"Policy Type\"].fillna(\"Basic\")\n",
    "insurance_test_data.loc[:, \"Previous Claims\"] = insurance_test_data[\"Previous Claims\"].fillna(0)\n",
    "insurance_test_data.loc[:, \"Vehicle Age\"] = insurance_test_data[\"Vehicle Age\"].fillna(0)\n",
    "insurance_test_data.loc[:, \"Credit Score\"] = insurance_test_data[\"Credit Score\"].fillna(0)\n",
    "insurance_test_data.loc[:, \"Insurance Duration\"] = insurance_test_data[\"Insurance Duration\"].fillna(0)\n",
    "insurance_test_data.dropna(subset=[\"Policy Start Date\"], inplace=True)\n",
    "insurance_test_data.loc[:, \"Customer Feedback\"] = insurance_test_data[\"Customer Feedback\"].fillna(\"Not Provided\")\n",
    "insurance_test_data.loc[:, \"Smoking Status\"] = insurance_test_data[\"Smoking Status\"].fillna(\"No\")\n",
    "insurance_test_data.loc[:, \"Exercise Frequency\"] = insurance_test_data[\"Exercise Frequency\"].fillna(\n",
    "    \"Not Provided\")\n",
    "insurance_test_data.loc[:, \"Property Type\"] = insurance_test_data[\"Property Type\"].fillna(\"Not Provided\")\n",
    "\n",
    "# Feature Engineering & Transformation (excluding Premium Amount)\n",
    "bins = [0, 5, 18, 25, 35, 45, 55, 65, float('inf')]  # Age bin edges\n",
    "labels = [\"High Risk (0-5) (Infants)\", \"Moderate Risk (6-18) (Children & Adolescents)\",\n",
    "          \"Low Risk (19-25) (Young Adults)\",\n",
    "          \"Moderate-Low Risk (26-35) (Early Adulthood)\", \"Moderate Risk (36-45) (Middle Adulthood)\",\n",
    "          \"High Risk (46-55) (Mature Adults)\", \"Very High Risk (56-65) (Pre-Retirement)\",\n",
    "          \"Very High Risk (65+) (Seniors)\"]\n",
    "insurance_test_data[\"Age_Bin\"] = pd.cut(insurance_test_data[\"Age\"], bins=bins, labels=labels, right=True)\n",
    "age_bin_mapping = {\n",
    "    \"High Risk (0-5) (Infants)\": 1,\n",
    "    \"Moderate Risk (6-18) (Children & Adolescents)\": 2,\n",
    "    \"Low Risk (19-25) (Young Adults)\": 3,\n",
    "    \"Moderate-Low Risk (26-35) (Early Adulthood)\": 4,\n",
    "    \"Moderate Risk (36-45) (Middle Adulthood)\": 5,\n",
    "    \"High Risk (46-55) (Mature Adults)\": 6,\n",
    "    \"Very High Risk (56-65) (Pre-Retirement)\": 7,\n",
    "    \"Very High Risk (65+) (Seniors)\": 8\n",
    "}\n",
    "insurance_test_data[\"Age_Bin Numeric\"] = insurance_test_data[\"Age_Bin\"].map(age_bin_mapping)\n",
    "insurance_test_data[\"Age_Bin Numeric\"] = insurance_test_data[\"Age_Bin Numeric\"].cat.codes\n",
    "\n",
    "if \"Gender\" in insurance_test_data.columns:\n",
    "    insurance_test_data = pd.get_dummies(insurance_test_data, columns=[\"Gender\"], drop_first=False)\n",
    "if 'Gender_Male' in insurance_test_data.columns:\n",
    "    insurance_test_data['Gender_Male'] = insurance_test_data['Gender_Male'].astype(int)\n",
    "if 'Gender_Female' in insurance_test_data.columns:\n",
    "    insurance_test_data['Gender_Female'] = insurance_test_data['Gender_Female'].astype(int)\n",
    "if 'Gender_Unknown' in insurance_test_data.columns:\n",
    "    insurance_test_data['Gender_Unknown'] = insurance_test_data['Gender_Unknown'].astype(int)\n",
    "income_bins = [0, 25000, 50000, 100000, 150000, float('inf')]  # Define bin edges\n",
    "income_labels = [\"Low Income (0-25k)\", \"Lower-Middle Income (25k-50k)\",\n",
    "                 \"Middle Income (50k-100k)\", \"Upper-Middle Income (100k-150k)\",\n",
    "                 \"High Income (150k+)\"]\n",
    "\n",
    "insurance_test_data[\"Income_Bin\"] = pd.cut(insurance_test_data[\"Annual Income\"], bins=income_bins,\n",
    "                                            labels=income_labels, right=False)\n",
    "income_bin_mapping = {\n",
    "    \"Low Income (0-25k)\": 1,\n",
    "    \"Lower-Middle Income (25k-50k)\": 2,\n",
    "    \"Middle Income (50k-100k)\": 3,\n",
    "    \"Upper-Middle Income (100k-150k)\": 4,\n",
    "    \"High Income (150k+)\": 5\n",
    "}\n",
    "insurance_test_data[\"Income_Bin Numeric\"] = insurance_test_data[\"Income_Bin\"].map(income_bin_mapping)\n",
    "insurance_test_data[\"Income_Bin Numeric\"] = insurance_test_data[\"Income_Bin Numeric\"].cat.codes\n",
    "\n",
    "if \"Marital Status\" in insurance_test_data.columns:\n",
    "    insurance_test_data = pd.get_dummies(insurance_test_data, columns=[\"Marital Status\"], drop_first=False)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "desired_order = [\"Unknown\", \"High School\", \"Bachelor's\", \"Master's\", \"PhD\"]\n",
    "label_encoder.classes_ = np.array(desired_order)\n",
    "insurance_test_data['Education Level_Encoded'] = label_encoder.transform(insurance_test_data['Education Level'])\n",
    "\n",
    "if \"Occupation\" in insurance_test_data.columns:\n",
    "    insurance_test_data['Occupation'] = insurance_test_data['Occupation'].replace({\n",
    "        'Employed': 'Employed/Self-Employed',\n",
    "        'Self-Employed': 'Employed/Self-Employed'\n",
    "    })\n",
    "    insurance_test_data = pd.get_dummies(insurance_test_data, columns=['Occupation'])\n",
    "if 'Occupation_Employed/Self-Employed' in insurance_test_data.columns:\n",
    "    insurance_test_data['Occupation_Employed/Self-Employed'] = insurance_test_data[\n",
    "        'Occupation_Employed/Self-Employed'].astype(int)\n",
    "if 'Occupation_Unemployed' in insurance_test_data.columns:\n",
    "    insurance_test_data['Occupation_Unemployed'] = insurance_test_data['Occupation_Unemployed'].astype(int)\n",
    "\n",
    "if \"Location\" in insurance_test_data.columns:\n",
    "    insurance_test_data = pd.get_dummies(insurance_test_data, columns=[\"Location\"], drop_first=False)\n",
    "if 'Location_Suburban' in insurance_test_data.columns:\n",
    "    insurance_test_data['Location_Suburban'] = insurance_test_data['Location_Suburban'].astype(int)\n",
    "if 'Location_Rural' in insurance_test_data.columns:\n",
    "    insurance_test_data['Location_Rural'] = insurance_test_data['Location_Rural'].astype(int)\n",
    "if 'Location_Urban' in insurance_test_data.columns:\n",
    "    insurance_test_data['Location_Urban'] = insurance_test_data['Location_Urban'].astype(int)\n",
    "if 'Location_Unknown' in insurance_test_data.columns:\n",
    "    insurance_test_data['Location_Unknown'] = insurance_test_data['Location_Unknown'].astype(int)\n",
    "\n",
    "if \"Policy Type\" in insurance_test_data.columns:\n",
    "    # Perform one-hot encoding for \"Policy Type\" if it hasn't been done already\n",
    "    insurance_test_data = pd.get_dummies(insurance_test_data, columns=[\"Policy Type\"], drop_first=False)\n",
    "if 'Policy Type_Basic' in insurance_test_data.columns:\n",
    "    insurance_test_data['Policy Type_Basic'] = insurance_test_data['Policy Type_Basic'].astype(int)\n",
    "if 'Policy Type_Comprehensive' in insurance_test_data.columns:\n",
    "    insurance_test_data['Policy Type_Comprehensive'] = insurance_test_data['Policy Type_Comprehensive'].astype(\n",
    "        int)\n",
    "if 'Policy Type_Premium' in insurance_test_data.columns:\n",
    "    insurance_test_data['Policy Type_Premium'] = insurance_test_data['Policy Type_Premium'].astype(int)\n",
    "\n",
    "skewed_features = ['Previous Claims']\n",
    "insurance_test_data[skewed_features] = insurance_test_data[skewed_features].apply(\n",
    "    lambda x: x + 1 if (x <= 0).any() else x)\n",
    "for col in skewed_features:\n",
    "    insurance_test_data[col], _ = boxcox(insurance_test_data[col])\n",
    "\n",
    "insurance_test_data['Policy Start Date'] = pd.to_datetime(insurance_test_data['Policy Start Date'],\n",
    "                                                           errors='coerce')\n",
    "insurance_test_data['Policy Start Year'] = insurance_test_data['Policy Start Date'].dt.year\n",
    "insurance_test_data['Policy Start Month'] = insurance_test_data['Policy Start Date'].dt.month\n",
    "insurance_test_data['Years Since Start'] = (pd.to_datetime('today') - insurance_test_data[\n",
    "    'Policy Start Date']).dt.days / 365\n",
    "insurance_test_data.drop(columns=[\"Policy Start Date\"], inplace=True)\n",
    "\n",
    "if \"Customer Feedback\" in insurance_test_data.columns:\n",
    "    insurance_test_data = pd.get_dummies(insurance_test_data, columns=[\"Customer Feedback\"], drop_first=False)\n",
    "if 'Customer Feedback_Poor' in insurance_test_data.columns:\n",
    "    insurance_test_data['Customer Feedback_Poor'] = insurance_test_data['Customer Feedback_Poor'].astype(int)\n",
    "if 'Customer Feedback_Average' in insurance_test_data.columns:\n",
    "    insurance_test_data['Customer Feedback_Average'] = insurance_test_data['Customer Feedback_Average'].astype(\n",
    "        int)\n",
    "if 'Customer Feedback_Good' in insurance_test_data.columns:\n",
    "    insurance_test_data['Customer Feedback_Good'] = insurance_test_data['Customer Feedback_Good'].astype(int)\n",
    "if 'Customer Feedback_Not Provided' in insurance_test_data.columns:\n",
    "    insurance_test_data['Customer Feedback_Not Provided'] = insurance_test_data[\n",
    "        'Customer Feedback_Not Provided'].astype(int)\n",
    "\n",
    "insurance_test_data['Smoking Status'] = insurance_test_data['Smoking Status'].map({'No': 0, 'Yes': 1})\n",
    "label_encoder = LabelEncoder()\n",
    "insurance_test_data['Smoking Status'] = label_encoder.fit_transform(insurance_test_data['Smoking Status'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "desired_order = [\"Not Provided\", \"Rarely\", \"Daily\", \"Weekly\", \"Monthly\"]\n",
    "label_encoder.classes_ = np.array(desired_order)\n",
    "insurance_test_data['Exercise Frequency Encoded'] = label_encoder.transform(\n",
    "    insurance_test_data['Exercise Frequency'])\n",
    "\n",
    "if \"Property Type\" in insurance_test_data.columns:\n",
    "    insurance_test_data = pd.get_dummies(insurance_test_data, columns=[\"Property Type\"], drop_first=False)\n",
    "if 'Property Type_House' in insurance_test_data.columns:\n",
    "    insurance_test_data['Property Type_House'] = insurance_test_data['Property Type_House'].astype(int)\n",
    "if 'Property Type_Apartment' in insurance_test_data.columns:\n",
    "    insurance_test_data['Property Type_Apartment'] = insurance_test_data['Property Type_Apartment'].astype(int)\n",
    "if 'Property Type_Condo' in insurance_test_data.columns:\n",
    "    insurance_test_data['Property Type_Condo'] = insurance_test_data['Property Type_Condo'].astype(int)\n",
    "if 'Property Type_Unknown' in insurance_test_data.columns:\n",
    "    insurance_test_data['Property Type_Unknown'] = insurance_test_data['Property Type_Unknown'].astype(int)\n",
    "\n",
    "# #### Handling Outliers (excluding Premium Amount)\n",
    "insurance_test_data['Number of Dependents'] = np.where(\n",
    "    insurance_test_data['Number of Dependents'] > 10, 10,\n",
    "    insurance_test_data['Number of Dependents']\n",
    ")\n",
    "\n",
    "Q1 = insurance_test_data['Health Score'].quantile(0.25)\n",
    "Q3 = insurance_test_data['Health Score'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "insurance_test_data = insurance_test_data[(insurance_test_data['Health Score'] >= lower_bound) &\n",
    "                                            (insurance_test_data['Health Score'] <= upper_bound)]\n",
    "\n",
    "bins = [-1, 0, 2, 5, 9, float('inf')]  # Define the bin edges\n",
    "labels = ['No Claims', 'Few Claims (1-2)', 'Moderate Claims (3-5)', 'High Claims (6-9)',\n",
    "          'Extreme Claims (9+)']  # Define the bin labels\n",
    "insurance_test_data['Previous Claims_Bin'] = pd.cut(insurance_test_data['Previous Claims'], bins=bins,\n",
    "                                                     labels=labels)\n",
    "previous_claims_bin_mapping = {\n",
    "    \"No Claims\": 1,\n",
    "    \"Few Claims (1-2)\": 2,\n",
    "    \"Moderate Claims (3-5)\": 3,\n",
    "    \"High Claims (6-9)\": 4,\n",
    "    \"Extreme Claims (9+)\": 5\n",
    "}\n",
    "insurance_test_data[\"Previous Claims_Bin Numeric\"] = insurance_test_data[\"Previous Claims_Bin\"].map(\n",
    "    previous_claims_bin_mapping)\n",
    "insurance_test_data[\"Previous Claims_Bin Numeric\"] = insurance_test_data[\"Previous Claims_Bin Numeric\"].cat.codes\n",
    "\n",
    "insurance_test_data['Vehicle Age'] = np.where(\n",
    "    insurance_test_data['Vehicle Age'] > 15, 15,\n",
    "    insurance_test_data['Vehicle Age']\n",
    ")\n",
    "\n",
    "Q1 = insurance_test_data['Credit Score'].quantile(0.25)\n",
    "Q3 = insurance_test_data['Credit Score'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "insurance_test_data = insurance_test_data[(insurance_test_data['Credit Score'] >= lower_bound) &\n",
    "                                            (insurance_test_data['Credit Score'] <= upper_bound)]\n",
    "\n",
    "bins = [-1, 1, 3, 8, float('inf')]  # Define the bin edges\n",
    "labels = ['New Clients (0-1)', 'Repeat Clients (2-3)', 'Established Clients (4-8)',\n",
    "          'Very Loyal Clients (9+)']  # Define the bin labels\n",
    "insurance_test_data['Insurance Duration_Bin'] = pd.cut(insurance_test_data['Insurance Duration'], bins=bins,\n",
    "                                                        labels=labels)\n",
    "insurance_duration_bin_mapping = {\n",
    "    \"New Clients (0-1)\": 1,\n",
    "    \"Repeat Clients (2-3)\": 2,\n",
    "    \"Established Clients (4-8)\": 3,\n",
    "    \"Very Loyal Clients (9+)\": 4\n",
    "}\n",
    "insurance_test_data[\"Insurance Duration_Bin Numeric\"] = insurance_test_data[\"Insurance Duration_Bin\"].map(\n",
    "    insurance_duration_bin_mapping)\n",
    "insurance_test_data[\"Insurance Duration_Bin Numeric\"] = insurance_test_data[\n",
    "    \"Insurance Duration_Bin Numeric\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to revert Box-Cox transformation\n",
    "def inv_boxcox_custom(y, lambda_value):\n",
    "    \"\"\"\n",
    "    Inverse Box-Cox transformation\n",
    "    y: transformed values\n",
    "    lambda_value: the lambda used in the original Box-Cox transformation\n",
    "    \"\"\"\n",
    "    if lambda_value == 0:\n",
    "        return np.exp(y)  # For lambda=0, use exp to revert log transformation\n",
    "    else:\n",
    "        return (y * lambda_value + 1) ** (1 / lambda_value)  # For lambda!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved!\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing\n",
    "X_test = insurance_test_data[['Age', 'Annual Income', 'Previous Claims', 'Credit Score',\n",
    "                          'Age_Bin Numeric', 'Income_Bin Numeric', 'Policy Start Year', \n",
    "                          'Years Since Start', 'Previous Claims_Bin Numeric']]\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# After prediction, revert the transformation on 'Premium Amount'\n",
    "lambda_value = 0.406  # Replace with the actual lambda value used for Box-Cox transformation\n",
    "y_pred_reverted = inv_boxcox_custom(y_pred, lambda_value)\n",
    "\n",
    "# Save submission file\n",
    "submission = pd.DataFrame({\"id\": insurance_test_data[\"id\"], \"Premium Amount\": y_pred_reverted})\n",
    "submission.to_csv(\"kaggle/working/submission.csv\", index=False)\n",
    "\n",
    "print(\"Submission file saved!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10305135,
     "isSourceIdPinned": false,
     "sourceId": 84896,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 262005,
     "modelInstanceId": 240359,
     "sourceId": 280539,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
